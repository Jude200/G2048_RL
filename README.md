# 2048 Game Project

Une implÃ©mentation complÃ¨te du jeu 2048 en Python avec une interface graphique moderne.

## ðŸ“‹ CaractÃ©ristiques

- âœ… MÃ©canique de jeu complÃ¨te (fusion de tuiles, gÃ©nÃ©ration alÃ©atoire)
- âœ… Interface graphique avec customtkinter
- âœ… Sauvegarde/chargement de parties
- âœ… Suivi du meilleur score
- âœ… ContrÃ´les au clavier (flÃ¨ches + WASD)
- âœ… DÃ©tection de victoire/dÃ©faite
- âœ… Tests unitaires
- âœ… Architecture modulaire et extensible

## ðŸ—ï¸ Architecture

```
src/
â”œâ”€â”€ main.py                 # Point d'entrÃ©e
â”œâ”€â”€ game/                   # Logique du jeu
â”‚   â”œâ”€â”€ board.py           # Gestion du plateau
â”‚   â”œâ”€â”€ game.py            # Gestionnaire de jeu
â”‚   â””â”€â”€ tile.py            # Classe tuile
â”œâ”€â”€ ui/                    # Interface graphique
â”‚   â”œâ”€â”€ gui.py             # FenÃªtre principale
â”‚   â”œâ”€â”€ styles.py          # ThÃ¨mes et couleurs
â”‚   â””â”€â”€ widgets.py         # Composants UI
â”œâ”€â”€ utils/                 # Utilitaires
â”‚   â”œâ”€â”€ constants.py       # Constantes du jeu
â”‚   â”œâ”€â”€ helpers.py         # Fonctions utilitaires
â”‚   â””â”€â”€ logger.py          # Logging
â””â”€â”€ storage/               # Persistance
    â””â”€â”€ save_manager.py    # Sauvegarde/chargement
```

## ðŸš€ Installation et utilisation

### Installation des dÃ©pendances

```bash
pip install -r requirements.txt
```

### Lancer le jeu

```bash
python -m src.main
```

## ðŸŽ® ContrÃ´les

- **FlÃ¨ches** : DÃ©placer les tuiles
- **WASD** : Alternative pour dÃ©placer
- **New Game** : Commencer une nouvelle partie
- **Undo** : Annuler le dernier coup (Ã  implÃ©menter)

## ðŸ“Š Structure des donnÃ©es

### Board (Plateau)

- `grid`: Matrice 4x4 des valeurs
- `score`: Score actuel
- `move_count`: Nombre de coups jouÃ©s

### GameManager (Gestionnaire)

- GÃ¨re l'Ã©tat global du jeu
- DÃ©tecte victoire/dÃ©faite
- GÃ¨re le meilleur score

## ðŸ§ª Tests

```bash
python -m unittest discover tests/
```

## ðŸ“ Prochaines Ã©tapes possibles

1. âœ¨ ImplÃ©mentation de l'Undo
2. ðŸ“Š Historique des scores
3. ðŸŽ¯ Niveaux de difficultÃ©
4. ðŸ”Š Effets sonores et animations
5. ðŸ“± Adaptation mobile
6. ðŸ¤– Mode IA

## ðŸ“„ Licence

Projet Ã©ducatif

def reward(self): # Si le jeu est fini, grosse pÃ©nalitÃ©
if self.is_game_over:
return -150.0

        grid = self.board.grid
        reward = 0.0

        # 1. RÃ‰COMPENSE DE FUSION (BasÃ©e sur les tuiles fusionnÃ©es au dernier tour)
        # On utilise log2 pour ne pas Ã©craser les autres rÃ©compenses avec des chiffres Ã©normes
        if self.board.merged_values:
            reward += sum([np.log2(v) for v in self.board.merged_values])

        # 2. BONUS DE CASES VIDES
        # Plus il y a de vide, plus l'agent est rÃ©compensÃ© (croissance non-linÃ©aire)
        empty_cells = len(self.board._get_empty_cells())
        if empty_cells > 0:
            reward += 0.5 * empty_cells # Bonus constant par case vide

        # 3. MONOTONIE (Alignement des tuiles)
        # On vÃ©rifie si les valeurs augmentent ou diminuent de maniÃ¨re constante
        # monotonicity = 0
        # # Lignes
        # for i in range(4):
        #     row = grid[i, :]
        #     # On ne compte que les cases non vides pour la monotonie
        #     values = row[row != 0]
        #     if len(values) > 1:
        #         diffs = np.diff(np.log2(values))
        #         if np.all(diffs <= 0) or np.all(diffs >= 0): # TriÃ© dans un sens
        #             monotonicity += sum(np.abs(diffs))
        # # Colonnes
        # for j in range(4):
        #     col = grid[:, j]
        #     values = col[col != 0]
        #     if len(values) > 1:
        #         diffs = np.diff(np.log2(values))
        #         if np.all(diffs <= 0) or np.all(diffs >= 0):
        #             monotonicity += sum(np.abs(diffs))

        # reward += 0.1 * monotonicity

        # 4. MATRICE DE POIDS (StratÃ©gie du coin)
        # On veut inciter l'IA Ã  mettre les grosses tuiles en haut Ã  gauche
        # weights = np.array([
        #     [100, 50, 20, 10],
        #     [50,  20, 10,  5],
        #     [20,  10,  5,  2],
        #     [10,   5,  2,  1]
        # ])

        snake_weights =  np.log2(np.array([
            [65536, 32768, 16384, 8192],
            [512, 1024, 2048, 4096],
            [256, 128, 64, 32],
            [2, 4, 8, 16]
        ]))

        # On multiplie log2(tuile) par le poids de sa position
        weighted_sum = 0
        for i in range(4):
            for j in range(4):
                if grid[i][j] > 0:
                    weighted_sum += np.log2(grid[i][j]) * snake_weights[i][j]

        # reward += 0.01 * weighted_sum
        # print("Reward:", reward)
        return reward

    # def reward(self) -> int:
    #     """Calculate reward based on current board state"""
    #     # Monotonie
    #     # monotonity_reward = ...

    #     # Empty Cell Reward
    #     empty_reward = len(self.board._get_empty_cells())

    #     # Weighted
    #     weights = np.array([[65536, 32768, 16384, 8192],
    #                         [512, 1024, 2048, 4096],
    #                         [256, 128, 64, 32],
    #                         [2, 4, 8, 16]])
    #     fusion_reward = np.sum(np.log2(weights * (self.board.grid + 1)))

    #     # Smoothness
    #     smoothness_reward = 0
    #     for i in range(self.board.size):
    #         for j in range(self.board.size):
    #             if self.board.grid[i][j] != 0:
    #                 value = np.log2(self.board.grid[i][j])
    #                 for neighbor in self.board.get_neighbors(i, j):
    #                     n_value = np.log2(self.board.grid[neighbor[0]][neighbor[1]]) if self.board.grid[neighbor[0]][neighbor[1]] != 0 else 0
    #                     smoothness_reward += abs(value - n_value)

    #     # End of game penalty
    #     end_penalty = -10 if self.is_game_over else 0

    #     # Total reward
    #     total_reward = int(0.1 * fusion_reward + 0.5 * empty_reward - 0.1 * smoothness_reward + end_penalty) / 16
    #     # print(f"Total Reward: {total_reward} | Fusion: {fusion_reward} | Empty: {empty_reward} | Smoothness: {smoothness_reward} | End Penalty: {end_penalty}")
    #     return total_reward * 2
